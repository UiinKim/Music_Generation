{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgYuIf3mlMFwDYbfruuh0X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UiinKim/Music_Generation/blob/main/audio_transform(audiolm_autoencoder).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audioldm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdDqlntCpuzb",
        "outputId": "2ebd9dbc-d478-4e2e-bfd4-f70fc2b5cdf5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: audioldm in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from audioldm) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchaudio>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from audioldm) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from audioldm) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audioldm) (4.66.5)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from audioldm) (4.41.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from audioldm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from audioldm) (0.8.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from audioldm) (5.2.0)\n",
            "Requirement already satisfied: numpy<=1.23.5 in /usr/local/lib/python3.10/dist-packages (from audioldm) (1.23.5)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from audioldm) (0.12.1)\n",
            "Requirement already satisfied: librosa==0.9.2 in /usr/local/lib/python3.10/dist-packages (from audioldm) (0.9.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from audioldm) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from audioldm) (2.1.4)\n",
            "Requirement already satisfied: torchlibrosa==0.0.9 in /usr/local/lib/python3.10/dist-packages (from audioldm) (0.0.9)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from audioldm) (4.42.4)\n",
            "Requirement already satisfied: progressbar in /usr/local/lib/python3.10/dist-packages (from audioldm) (2.5)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from audioldm) (6.2.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->audioldm) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->audioldm) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->audioldm) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->audioldm) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->audioldm) (0.4.3)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->audioldm) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->audioldm) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->audioldm) (24.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->audioldm) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->audioldm) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->audioldm) (12.6.20)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.14.0->audioldm) (9.4.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->audioldm) (0.2.13)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (3.7.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (0.112.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (6.4.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (3.7.1)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (3.10.7)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (2.8.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (0.5.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (0.12.3)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audioldm) (0.30.5)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio->audioldm) (12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->audioldm) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->audioldm) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->audioldm) (2024.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->audioldm) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->audioldm) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->audioldm) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->audioldm) (0.19.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->audioldm) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->audioldm) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->audioldm) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->audioldm) (2.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->audioldm) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->audioldm) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->audioldm) (0.14.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audioldm) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audioldm) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audioldm) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audioldm) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audioldm) (3.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa==0.9.2->audioldm) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.2->audioldm) (4.2.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->audioldm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->audioldm) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->audioldm) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->audioldm) (3.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.2->audioldm) (3.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->audioldm) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->audioldm) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->audioldm) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->audioldm) (0.37.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->audioldm) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->audioldm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->audioldm) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->audioldm) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0pmmWxXqpm8e"
      },
      "outputs": [],
      "source": [
        "#audiolm/variational_autoencoder/autoencoder\n",
        "\n",
        "import torch\n",
        "from audioldm.latent_diffusion.ema import *\n",
        "from audioldm.variational_autoencoder.modules import Encoder, Decoder\n",
        "from audioldm.variational_autoencoder.distributions import DiagonalGaussianDistribution\n",
        "\n",
        "from audioldm.hifigan.utilities import get_vocoder, vocoder_infer\n",
        "\n",
        "class AutocoderKL(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        ddconfig=None, #인코더, 디코더의 설정 정보\n",
        "        lossconfig=None, #손실함수 설정 정보\n",
        "        image_key='fbank', #입력 데이터의 유형 설정. fbank(필터뱅크),stft(단시간 푸리에 변환) --> 바꿔보기\n",
        "        embed_dim=None, #latent space의 차원\n",
        "        time_shuffle=1,\n",
        "        subband=1, #subband 분해를 제어, 다양한 주파수 대역을 분리하여 처리 가능\n",
        "        ckpt_path=None, #모델 가중치를 로드하기 위한 체크포인트 파일 경로\n",
        "        reload_from_ckpt=None,\n",
        "        ignore_keys=[],\n",
        "        colorize_nlabels=None,\n",
        "        monitor=None,\n",
        "        base_learning_rate=1e-5,\n",
        "        scale_factor=1\n",
        "  ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder=Encoder(**ddconfig)\n",
        "        self.decoder=Decoder(**ddconfig)\n",
        "\n",
        "        self.subband=int(subband)\n",
        "\n",
        "        if self.subband>1:\n",
        "          print(\"Use subband decomposition %s\" % self.subband)\n",
        "\n",
        "        #양자화 컨볼루션 : latent vecotr로 변환하기 위한 컨볼루션 레이어\n",
        "        self.quant_conv=torch.nn.Conv2d(2*ddconfig['z_channels'],2*embed_dim,1) #encoder에서 잠재표현으로\n",
        "        self.post_quant_conv=torch.nn.Conv2d(embed_dim, ddconfig[\"z_channels\"], 1) #잠재표현에서 decoder로\n",
        "\n",
        "        self.vocoder=get_vocoder(None, 'cpu') #HiFi-GAN을 사용하여 스펙트로그램과 같은 오디오 표현을 파형으로 변환하는 역할인 vocoder을 초기화\n",
        "        self.embed_dim=embed_dim\n",
        "\n",
        "        if monitor is not None: #모니터링 옵션 설정\n",
        "          self.monitor=monitor\n",
        "\n",
        "        self.time_shuffle=time_shuffle\n",
        "        self.reload_from_ckpt=reload_from_ckpt\n",
        "        self.reloaded=False\n",
        "        self.mean, self.std=None, None\n",
        "\n",
        "        self.scale_factor=scale_factor\n",
        "\n",
        "    def encode(self, x):\n",
        "      #x=self.time_shuffle_operation(x)\n",
        "      x=self.freq_split_subband(x) #서브밴드 분해가 활성화일 경우, input audio feature을 개별 주파수 밴드로 나눈다\n",
        "      h=self.encoder(x) #인코더로 input data 처리\n",
        "      moments=self.quant_conv(h) #양자화 컨볼루션을 통해 가우시안 분포의 모멘트(평균과 로그 분산) 생성\n",
        "      posterior=DiagonalGaussianDistribution(moments) #모멘트로부터 latent vector샘플링\n",
        "      return posterior\n",
        "\n",
        "    def decode(self, z):\n",
        "      z=self.post_quant_conv(z) #양자화 후 컨볼루션으로 latent vector z를 디코더가 처리할 수 있는 형태로 변환\n",
        "      dec=self.decoder(z) #디코더를 사용하여 latent space-> 원래 데이터로 복원\n",
        "      dec=self.freq_merge_subband(dec) #subband 분해가 수행된 경우, 주파수 밴드를 병합하여 전체 주파수 표현을 복원\n",
        "      return dec\n",
        "\n",
        "    def decode_to_waveform(self, dec):\n",
        "      dec=dec.squeeze(1).permute(0,2,1) #디코더의 output의 형태를 vocoder에 맞게 조정\n",
        "      wav_reconstruction=vocoder_infer(dec, self.vocoder) #보코더를 사용하여 dec을 파형으로 변환\n",
        "      return wav_reconstruction\n",
        "\n",
        "    def forward(self, input, sample_posterior=True):\n",
        "      posterior=self.encode(input) #input을 인코딩하여 posterior 분포를 얻는다\n",
        "      #파라미터에 대한 확률 분포\n",
        "      #잠재 벡터를 샘플링하거나 모드 값 사용\n",
        "      if sample_posterior:\n",
        "        z=posterior.sample() #posterior분포에 대해 표본을 생성\n",
        "      else:\n",
        "        z=posterior.mode() #확률 분포에서 가장 확률이 높은 값\n",
        "\n",
        "      if self.flag_first_run: #초기데이터 불러러오기\n",
        "        print(\"Latent size: \", z.size())\n",
        "        self.flag_first_run=False\n",
        "\n",
        "      dec=self.decode(z) #잠재 벡터를 디코딩하여 데이터 복원\n",
        "\n",
        "      return dec, posterior #복원 데이터와 posterior 분포 반환\n",
        "\n",
        "    def freq_split_subband(self, fbank): #fbank(stft와 같은 스펙트로그램을 나타내는 텐서)를 입력받아 특정 조건에 따라 여러 개의 subband로 나누어 반환\n",
        "      if self.subband==1 or self.image_key != \"stft\": #subband 처리가 필요한지 확인 -> 1이면 subband로 나눌 필요가 없으며 stft가 아닌 경우에도 필요 없음\n",
        "      #self.subband는 subband의 수, image_key는 신호 처리의 유형\n",
        "        return fbank\n",
        "\n",
        "      bs, ch, tstep, fbins=fbank.size() #fbank의 각 텐서의 크기 반환\n",
        "      #batch_size, channels, timesteps, frequency bins\n",
        "\n",
        "      assert fbank.size(-1) % self.subband==0 #subband로 나누기 위해서는 frequency bins의 수가 subband의 수로 균등하게 나눠져야 함\n",
        "      assert ch == 1 #이 코드는 단일 채널 input에 대해서만 작동\n",
        "\n",
        "      return (\n",
        "          fbank.squeeze(1).reshape(bs, tstep, self.subbnad, fbins // self.subband).permute(0, 2, 1, 3)\n",
        "          #chnnels의 차원이 1일때 해당 차원을 제거([bs, 1, tsteps, fbins]->[bs, tsteps, fbins])\n",
        "          #.reshape로 fbank를 재구성하여 [bs, tstep, fbins] 형태의 텐서를 [bs, tsetp, self.subband, fbins//self.subband]로 재구성\n",
        "          #.premute(0,2,1,3)로 차원 순서 변경하여 [bs, tstep, self.subband, fbins//self.subband]로 변환하여  배치와 subband 별로 구분된 데이터로 만들기\n",
        "      )\n",
        "\n",
        "    def freq_merge_subband(self, subband_fbank):\n",
        "      if self.subband==1 or self.image_key != 'stft':\n",
        "        return subband_fbank\n",
        "\n",
        "      assert subband_fbank.size(1)==self.subband #channel dimension. self.subband와 크기(subband의 개수)가 같아야 함\n",
        "      bs, sub_ch, tstep, fbins = subband_fbank.size() #각 fbank의 각 텐서 크기 반환\n",
        "      return subband_fbank.permute(0, 2, 1, 3).reshape(bs, tstep, -1).unsqueeze(1)\n",
        "      #다시 순서를 [bs, tstep, sub_ch, fbins]로 변경\n",
        "      #.reshape으로 sub_ch과 fbins를 곱하여 sub_ch*fbins로 나타나짐(subband가 하나의 큰 주파수로 합쳐짐)\n",
        "      #.unsqueeze로 새로운 차원을 추가하여 [bs, 1, tstep, sub_ch*fbins]로 만들어 4차원 텐서로 다시 반환 -> 입력 텐서와 같은 형태\n",
        "\n",
        "    #모델의 파라미터가 위치한 디바이스(gpu or cpu)를 반환\n",
        "    def device(self):\n",
        "      return next(self.parameters()).device\n",
        "\n",
        "    @torch.no_grad() #이 함수 내에서 실행되는 모든 연산에 대해 gradient를 계산하지 않도록 (모델의 추론단계 사용)\n",
        "    #인코딩 method의 gradient가 없는 버전으로 inference할때 gradient 사용 x\n",
        "    def encode_first_stage(self, x):\n",
        "      return self.encode(x)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def decode_first_stage(self, z, predict_cids=False, force_not_quantize=False):\n",
        "    #z는 입력 텐서(모델의 디코딩 대상), predict_cids는 특정 단계 'z'를 처리할지 여부를 결정, force_not_quantize는 양자화를 강제로 비활성화할지 여부\n",
        "      if predict_cids: #z를 처리하는 경우\n",
        "        if z.dim() == 4: #z가 4차원의 텐서인지 확인\n",
        "          z = torch.argmax(z.exp(), dim=1).long() #z의 지수함수에서 가장 큰 값을 가지는 인덱스를 반환하여 long타입으로 변환\n",
        "        z = self.first_stage_model.quantize.get_codebook_entry(z, shape=None) #z를 양자화된 코드북으로 변환 (벡터 양자화)\n",
        "        z = z.permute(0, 3, 1, 2).contiguous() #z의 차원을 재배열하고 메모리 상에서 연속적인 형태로 만든다.\n",
        "\n",
        "      z = 1.0 / self.scale_factor * z #z의 크기를 조정하는 과정, 모델의 학습 및 추론에서 사용된 스케일링을 되돌리기\n",
        "      return self.decode(z) #z 디코딩\n",
        "\n",
        "    def get_first_stage_encoding(self, encoder_posterior): #잠재변수 입력인 encoder_posterior의 유형에 따라 함수가 다르게 동작\n",
        "      if isinstance(encoder_posterior, DiagonalGaussianDistribution): #가우시안 분포 타입인 경우\n",
        "        z = encoder_posterior.sample() #sampling된 값을 z에 할당\n",
        "      elif isinstance(encoder_posterior, torch.Tensor): #텐서인 경우\n",
        "        z = encoder_posterior #입력 그대로를 사용\n",
        "      else: #두 가지 외의 타입이면 에러 발생\n",
        "        raise NotImplementedError(\n",
        "            f\"encoder_posterior of type '{type(encoder_posterior)}' not yet implemented\"\n",
        "        )\n",
        "      return self.scale_factor * z #z를 스케일링(잠재 변수 크기 조정)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#audiolm/variational_autoencoder/distributions\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class AbstractDistribution:\n",
        "  def sample(self): #샘플 생성 기능, 다른 클래스 상속\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def mode(self): #가장 가능성이 높은 값을 반환, 다른 클래스 상속\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "class DiracDistribution(AbstractDistribution): #샘플링이 항상 같은 값 반환\n",
        "  def __init__(self, value):\n",
        "    self.value=value\n",
        "\n",
        "  def sample(self):\n",
        "    return self.value\n",
        "\n",
        "  def mode(self):\n",
        "    return self.value\n",
        "\n",
        "\n",
        "class DiagonalGaussianDistribution(object): #가우시안 분포의 대각선 형태 -> VAE or 다른 베이지안 모델에서 잠재 변수 분포 모델링\n",
        "  def __init__(self, parameters, deterministic=False):\n",
        "  #parameters : 가우시안 분포의 평균과 분산 계산에 사용\n",
        "  #deterministic : True로 설정되면 무작위성을 제거하고 항상 동일한 결과 반환\n",
        "    self.parameters = parameters\n",
        "    self.mean, self.logvar = torch.chunk(parameters, 2, dim=1) #parameter을 mean과 logvar 2개로 분리, dim=1은 텐서의 두번째 차원에서 나눔\n",
        "    self.logvar = torch.clamp(self.logvar, -30.0, 20.0) #logvar은 로그 스케일에서의 분산을 의미 -> 이 값을 통해 분산과 표준편차를 계산할 수 있음\n",
        "    #로그 분산 값이 너무 작거나 커지는 것을 방지(극단적인 값)\n",
        "    self.deterministic = deterministic #determinisitc 상속\n",
        "    self.std = torch.exp(0.5 * self.logvar) # 0.5*self.logvar로 로그 스케일에서 표준편차에 해당하는 값을 계산하고 torch.exp를 적용하여 원래 스케일로 변환\n",
        "    self.var = torch.exp(self.logvar) #로그 분산을 지수함수로 변환하여 분산 값 계산\n",
        "    if self.dterministic: #True일 경우 분산(self.var)과 표준편차(self.std)를 0으로 설정\n",
        "      self.var = self.std = torch.zeros_like(self.mean).to( #mean과 동일한 크기의 텐서를 0으로 채워 생성, parameter과 동일한 디바이스에 저장 -> 무작위성 제거, 샘플링시 평균값만 반환\n",
        "          device=self.parameters.device\n",
        "      )\n",
        "\n",
        "  def sample(self): #가우시안 분포의 평균과 표준편차로 무작위 샘플 생성 -> 잠재변수 샘플링(VAE 모델에서의)에 사용됨\n",
        "    x = self.mean + self.std * torch.randn(self.mean.shape).to(\n",
        "        #torch.randn(self.mean.shape)은 평균이 0이고 분산이 1인 표준 정규 분포에서 랜덤 샘플 생성 -> 분포의 표준 편차로와 곱하여 조정하고 평균을 더하여 원하는 가우시안 분포에서의 샘플 생성\n",
        "        device=self.parameters.device\n",
        "    )\n",
        "    return x\n",
        "\n",
        "  def kl(self, other=None):\n",
        "    if self.deterministic: #determinisitic이 True이면 무작위성이 없는 결정론적 분포\n",
        "      return torch.Tensor([0.0]) #KL발산은 0으로 설정\n",
        "    else:\n",
        "      if other is None: #deterministic이 False이고 other이 None일 경우\n",
        "        return 0.5*torch.mean(\n",
        "            torch.pow(self.mean, 2)+self.var-1.0-self.logvar,\n",
        "            #torch.pow(self.mean, 2) : 평균의 제곱을 하여 표준 정규 분포와 비교할 때 현재 분포의 중심에서 얼마나 벗어나있는지 측정\n",
        "            #현재 분포의 분산에서 표준 정규의 분산인 1을 빼고 로그 분산을 빼서 비슷한 스케일로 표현\n",
        "            dim=[1,2,3],\n",
        "            #이후 각 0차원을 제외한 1차원, 2차원, 3차원에서의 평균을 계산하여 스칼라 값이 된다.\n",
        "        ) #최종적으로 KL발산에 0.5를 곱하여 반환\n",
        "      else:\n",
        "        return 0.5*torch.mean(\n",
        "            torch.pow(self.mean-other.mean, 2) / other.var #현재 분포와 other의 분포의 평균의 차이를'other'의 분산으로 나누어 정규화 -> 두 분포의 중심이 얼마나 떨어져 있는지 나타냄\n",
        "            + self.var / other.var #현재 분포의 분산을 'other' 분포의 분산으로 나누어 두 분포의 스케일 차이를 반영\n",
        "            - 1.0 #KL발산의 공식에서 등장하는 상수(표준 정규 분포의 분산인 1을 빼준다)\n",
        "            - self.logvar + other.logvar, #두 분포의 로그 분산의 차이를 반영. 로그 분산 차이는 분포의 스케일(분산, 표준편차) 차이를 반영\n",
        "            dim=[1,2,3],  #결과의 평균을 계산하여 KL 발산 값을 배치 차원과 공간 차원에서 평균화\n",
        "        ) #최종적으로 KL발산 값에 0.5를 곱하여 반환\n",
        "\n",
        "  def nll(self, sample, dims=[1,2,3]): #가우시안 분포에서의 Negative Log-Likelihood 계산\n",
        "  #NLL은 주어진 데이터가 특정 분포에 따라 관찰될 가능성의 대칭적인 척도 -> 주어진 샘플이 해당 분포로부터 얼마나 가능성이 있는지 측정하는 함수\n",
        "  #sample : NLL을 계산할 샘플(데이터)이며 self.mean과 self.var로 정의된 가우시안 분포에 대해 평가됨\n",
        "  #dims=[1,2,3]은 4차원 텐서에서 첫번째 차원을 제외한 모든 차원\n",
        "    if self.determinisitic: #deterministic이 True일 경우 NLL을 0으로 반환\n",
        "      return torch.Tensor([0.0])\n",
        "    logtwopi=np.log(2.0 * np.pi) #log(2ㅠ)를 계산한 값 -> 가우시안 분포의 NLL 계산에서 상수항으로 사용\n",
        "    return 0.5 * torch.sum(\n",
        "        logtwopi + self.logvar + torch.pow(sample - self.mean, 2) / self.var,\n",
        "        #log(2ㅠ)상수항 + 현재 분포의 로그분산 + 샘플과 분포의 평균 사이의 제곱 오차를 분산으로 나눈 값\n",
        "        dim=dims, #1차원인 배치 차원을 제외한 각 차원에 대해 NLL 값을 계산하여 [batch_size]크기의 텐서를 반환 -> batch_size개의 3개의 NLL 값\n",
        "    ) #0.5를 곱하여 가우시안 분포의 NLL식을 완성\n",
        "\n",
        "  def mode(self):\n",
        "    return self.mean\n",
        "\n",
        "\n",
        "#두 개의 가우시안 분포 사이의 KL발산을 계산(두 확률 분포 간의 차이를 측정)\n",
        "def normal_kl(mean1, logvar1, mean2, logvar2): #첫번째 가우시안 분포의 평균과 로그분산, 두번째 가우시안 분포의 평균과 로그분산\n",
        "  \"\"\"\n",
        "  source : https://github.com/openai/guided-diffusion/blob/27c20a8fab9cb472df5d6bdd6c8d11c8f430b924/guided_diffusion/losses.py#L12\n",
        "  Compute the KL divergence between two gaussians.\n",
        "  Shapes are automatically broadcasted, so batches can be compared to\n",
        "  scalars, among other use cases.\n",
        "  \"\"\"\n",
        "  #이 함수는 두 가우시안 분포 간의 KL 발산을 계산하여, 그 값을 반환합니다. 로그 분산이 제공된다는 점에서, 이 함수는 로그 스케일에서 분산을 다루고 있습니다.\n",
        "\n",
        "  #네 개의 매개변수(mean1, logvar1, mean2, logvar2) 중 하나가 반드시 텐서 객체인지 확인하는 코드\n",
        "  tensor = None #초기에는 None으로 설정\n",
        "  for obj in (mean1, logvar1, mean2, logvar2):\n",
        "    if isinstance(obj, torch.Tensor): #텐서 객체가 발견되면 그 객체를 tensor 변수에 할당\n",
        "      tensor=obj\n",
        "      break\n",
        "  assert tensor is not None, \"at least one argument must be a Tensor\" #최소 하나의 input이 텐서여야 하며 아니면 에러 출력\n",
        "\n",
        "  # Force variances to be Tensors. Broadcasting helps convert scalars to\n",
        "  # Tensors, but it does not work for torch.exp().\n",
        "  logvar1, logvar2 = [\n",
        "      x if isinstance(x, torch.Tensor) else torch.tensor(x).to(tensor) for x in (logvar1, logvar2)\n",
        "      #logvar1, logvar2가 텐서가 아닌 경우 텐서로 변환하고 tensor 변수가 있는 동일한 장치(gpu, cpu)로 이동\n",
        "  ]\n",
        "\n",
        "  return 0.5 * ( #두 가우시안 분포 사이의 KL발산을 계산하는 수식\n",
        "      - 1.0\n",
        "      + logvar2\n",
        "      - logvar1 #로그 분산 비율을 계산\n",
        "      + torch.exp(logvar1 - logvar2) #두 분포의 분산 비율을 계산\n",
        "      + ((mean1 - mean2) ** 2) * torch.exp(-logvar2) #두 분포의 평균 차이에 대한 비율을 계산\n",
        "  )"
      ],
      "metadata": {
        "id": "EKWXgCIv-r9W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_V8io-vwZhgp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}